#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import re
import pandas as pd
import os
import glob
import sys
import argparse

def format_text(text):
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‚’æ•´å½¢ã™ã‚‹ã€‚ã€Œå·ã€ãƒ¬ãƒ™ãƒ«ï¼ˆ(1), (2), ï¼ˆ1ï¼‰ãªã©ï¼‰ã¨
    ã‚«ã‚¿ã‚«ãƒŠï¼ˆã‚¢ã€ã‚¤ã€ã‚¦ãªã©ï¼‰ã§å§‹ã¾ã‚‹è¡Œã®å‰ã®æ”¹è¡Œã‚’å‰Šé™¤ã™ã‚‹ã€‚
    
    Parameters:
    - text: å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
    
    Returns:
    - formatted_text: æ•´å½¢ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
    """
    # è¡Œã”ã¨ã«åˆ†å‰²
    lines = text.split('\n')
    
    # æ•´å½¢å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ ¼ç´y
    formatted_lines = []
    
    for i, line in enumerate(lines):
        line_stripped = line.strip()
        
        # ç©ºè¡Œã¯ã‚¹ã‚­ãƒƒãƒ—
        if not line_stripped:
            continue
        
        # ã€Œå·ã€ãƒ‘ã‚¿ãƒ¼ãƒ³: (1), (2), ï¼ˆ1ï¼‰, ï¼ˆ2ï¼‰ ãªã©ï¼ˆæ‹¬å¼§+æ•°å­—ï¼‰ã§å§‹ã¾ã‚‹è¡Œ
        is_gou = re.match(r'^[ï¼ˆ\(]\d+[ï¼‰\)]', line_stripped)
        
        # ã‚«ã‚¿ã‚«ãƒŠãƒ‘ã‚¿ãƒ¼ãƒ³: ã‚¢ã€ã‚¤ã€ã‚¦ã€ã‚¨ã€ã‚ª ãªã©ã§å§‹ã¾ã‚‹è¡Œ
        is_katakana = re.match(r'^[ã‚¡-ãƒ¶ãƒ¼]+[\sã€€]', line_stripped) or re.match(r'^[ã‚¡-ãƒ¶ãƒ¼]+$', line_stripped) or re.match(r'^[ã‚¡-ãƒ¶ãƒ¼]+[^ã‚¡-ãƒ¶ãƒ¼]', line_stripped)
        
        if (is_gou or is_katakana) and formatted_lines:
            # å·ã¾ãŸã¯ã‚«ã‚¿ã‚«ãƒŠã®å ´åˆã¯æ”¹è¡Œã›ãšã€ç›´å‰ã®è¡Œã«é€£çµ
            # å‰ã®è¡Œã®æœ«å°¾ã«ã€Œã€‚ã€ãŒãªã„å ´åˆã¯è¿½åŠ 
            if not formatted_lines[-1].endswith('ã€‚'):
                formatted_lines[-1] += 'ã€‚'
            formatted_lines[-1] += line_stripped
        else:
            # ãã‚Œä»¥å¤–ï¼ˆæ¡ã€é …ãªã©ï¼‰ã¯æ”¹è¡Œã‚’ä¿æŒ
            formatted_lines.append(line_stripped)
    
    # æ•´å½¢ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆ
    formatted_text = '\n'.join(formatted_lines)
    
    return formatted_text

def extract_metadata_from_filename(filename):
    """
    ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰è‡ªæ²»ä½“åã¨åŒºåˆ†ã‚’æŠ½å‡ºã™ã‚‹
    ä¾‹: "èŠ³è³€ç”º_Haga_Town_Ordinance_PDF.txt" -> ("èŠ³è³€ç”º", "æ¡ä¾‹")
        "Haga_Town_Ordinance_PDF.txt" -> ("Haga Town", "æ¡ä¾‹")
        "Haga_Town_Regulation_HTML.txt" -> ("Haga Town", "æ–½è¡Œè¦å‰‡")
    
    Parameters:
    - filename: ãƒ•ã‚¡ã‚¤ãƒ«å
    
    Returns:
    - jichitai: è‡ªæ²»ä½“å
    - kubun: åŒºåˆ†
    """
    # æ‹¡å¼µå­ã‚’é™¤å»
    name = os.path.splitext(filename)[0]
    
    # "_PDF", "_HTML", "_Ordinance", "_Regulation" ãªã©ã®ãƒã‚¤ã‚ºã‚’é™¤å»
    # åŒºåˆ†ã‚’åˆ¤å®š
    if 'Ordinance' in name:
        kubun = 'æ¡ä¾‹'
        name = name.replace('_Ordinance', '')
    elif 'Regulation' in name:
        kubun = 'æ–½è¡Œè¦å‰‡'
        name = name.replace('_Regulation', '')
    else:
        kubun = 'ä¸æ˜'
    
    # PDFã‚„HTMLã®ãƒã‚¤ã‚ºã‚’é™¤å»
    name = name.replace('_PDF', '').replace('_HTML', '')
    
    # æ—¥æœ¬èªã¨è‹±èªãŒæ··åœ¨ã—ã¦ã„ã‚‹å ´åˆã€æ—¥æœ¬èªã‚’å„ªå…ˆ
    # ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã§åˆ†å‰²
    parts = name.split('_')
    
    # æ—¥æœ¬èªã‚’å«ã‚€éƒ¨åˆ†ã‚’æ¢ã™
    japanese_parts = []
    for part in parts:
        # æ—¥æœ¬èªæ–‡å­—ï¼ˆã²ã‚‰ãŒãªã€ã‚«ã‚¿ã‚«ãƒŠã€æ¼¢å­—ï¼‰ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if re.search(r'[ã-ã‚“ã‚¡-ãƒ¶ä¸€-é¾¥]', part):
            japanese_parts.append(part)
    
    # æ—¥æœ¬èªãŒã‚ã‚‹å ´åˆã¯æ—¥æœ¬èªã‚’å„ªå…ˆã€ãªã‘ã‚Œã°è‹±èªéƒ¨åˆ†ã‚’ä½¿ç”¨
    if japanese_parts:
        jichitai = '_'.join(japanese_parts)
    else:
        # è‹±èªã®å ´åˆã¯ã‚¹ãƒšãƒ¼ã‚¹ã«å¤‰æ›
        jichitai = name.replace('_', ' ').strip()
    
    return jichitai, kubun

def get_available_years():
    """åˆ©ç”¨å¯èƒ½ãªå¹´åˆ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒªã‚¹ãƒˆã‚’å–å¾—"""
    years = set()
    
    # out_xxxxå½¢å¼ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¤œç´¢
    pattern = "out_*"
    dirs = glob.glob(pattern)
    for d in dirs:
        if os.path.isdir(d):
            match = re.search(r'out_(\d{4})$', d)
            if match:
                years.add(match.group(1))
    
    # out_txt_xxxxå½¢å¼ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¤œç´¢
    pattern = "out_txt_*"
    dirs = glob.glob(pattern)
    for d in dirs:
        if os.path.isdir(d):
            match = re.search(r'out_txt_(\d{4})$', d)
            if match:
                years.add(match.group(1))
    
    return sorted(list(years))

def parse_year_range(year_input):
    """å¹´ã®ç¯„å›²æ–‡å­—åˆ—ã‚’è§£æã—ã¦å¹´ã®ãƒªã‚¹ãƒˆã‚’è¿”ã™"""
    if not year_input:
        return []
    
    if '-' in year_input:
        # ç¯„å›²æŒ‡å®šï¼ˆä¾‹: 2014-2018ï¼‰
        try:
            start_year, end_year = year_input.split('-', 1)
            start_year = int(start_year.strip())
            end_year = int(end_year.strip())
            if start_year > end_year:
                print(f"ã‚¨ãƒ©ãƒ¼: é–‹å§‹å¹´ï¼ˆ{start_year}ï¼‰ãŒçµ‚äº†å¹´ï¼ˆ{end_year}ï¼‰ã‚ˆã‚Šå¤§ãã„ã§ã™ã€‚")
                sys.exit(1)
            return [str(year) for year in range(start_year, end_year + 1)]
        except ValueError:
            print(f"ã‚¨ãƒ©ãƒ¼: å¹´ã®ç¯„å›²æŒ‡å®šãŒç„¡åŠ¹ã§ã™: {year_input}")
            print("æ­£ã—ã„å½¢å¼: YYYY-YYYY (ä¾‹: 2014-2018)")
            sys.exit(1)
    else:
        # å˜å¹´æŒ‡å®šï¼ˆä¾‹: 2015ï¼‰
        try:
            year = int(year_input.strip())
            return [str(year)]
        except ValueError:
            print(f"ã‚¨ãƒ©ãƒ¼: å¹´ã®æŒ‡å®šãŒç„¡åŠ¹ã§ã™: {year_input}")
            print("æ­£ã—ã„å½¢å¼: YYYY ã¾ãŸã¯ YYYY-YYYY (ä¾‹: 2015 ã¾ãŸã¯ 2014-2018)")
            sys.exit(1)

def extract_year_from_directory(directory):
    """
    ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã‹ã‚‰åˆ¶å®šå¹´ã‚’æŠ½å‡ºã™ã‚‹
    ä¾‹: "out_2022" -> "2022"
        "out_txt_2023" -> "2023"
    
    Parameters:
    - directory: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå
    
    Returns:
    - year: åˆ¶å®šå¹´ï¼ˆæ–‡å­—åˆ—ï¼‰ã€æŠ½å‡ºã§ããªã„å ´åˆã¯None
    """
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã‹ã‚‰4æ¡ã®æ•°å­—ã‚’æŠ½å‡º
    match = re.search(r'(\d{4})', directory)
    if match:
        return match.group(1)
    return None

def get_target_directories(years=None):
    """
    å‡¦ç†å¯¾è±¡ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒªã‚¹ãƒˆã‚’å–å¾—
    out_xxxx ã¨ out_txt_xxxx ã®ä¸¡æ–¹ã‚’å¯¾è±¡ã¨ã™ã‚‹
    
    Parameters:
    - years: å¯¾è±¡å¹´ã®ãƒªã‚¹ãƒˆã€‚Noneã®å ´åˆã¯å…¨ã¦ã®åˆ©ç”¨å¯èƒ½ãªå¹´
    
    Returns:
    - directories: å­˜åœ¨ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒªã‚¹ãƒˆ
    """
    if years is None:
        years = get_available_years()
    
    directories = []
    missing_years = []
    
    for year in years:
        year_dirs = []
        
        # out_xxxxå½¢å¼ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒã‚§ãƒƒã‚¯
        out_dir = f"out_{year}"
        if os.path.exists(out_dir) and os.path.isdir(out_dir):
            year_dirs.append(out_dir)
        
        # out_txt_xxxxå½¢å¼ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒã‚§ãƒƒã‚¯
        out_txt_dir = f"out_txt_{year}"
        if os.path.exists(out_txt_dir) and os.path.isdir(out_txt_dir):
            year_dirs.append(out_txt_dir)
        
        if year_dirs:
            directories.extend(year_dirs)
        else:
            missing_years.append(year)
    
    if missing_years:
        print(f"è­¦å‘Š: ä»¥ä¸‹ã®å¹´ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {', '.join(missing_years)}")
        print("       å¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå½¢å¼: out_YYYY, out_txt_YYYY")
    
    return directories

def process_multiple_files(directories, output_csv):
    """
    è¤‡æ•°ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€æ•´å½¢ã—ã¦CSVã«ã¾ã¨ã‚ã‚‹
    ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã‹ã‚‰åˆ¶å®šå¹´ã‚’è‡ªå‹•åˆ¤å®šã™ã‚‹
    
    Parameters:
    - directories: ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒæ ¼ç´ã•ã‚Œã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒªã‚¹ãƒˆ
    - output_csv: å‡ºåŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    
    Returns:
    - success_count: æˆåŠŸã—ãŸä»¶æ•°
    - error_count: ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸä»¶æ•°
    - duplicate_count: é‡è¤‡ã—ãŸä»¶æ•°
    """
    all_data = []
    success_count = 0
    error_count = 0
    duplicate_count = 0
    
    # å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¨˜éŒ²ã™ã‚‹ã‚»ãƒƒãƒˆï¼ˆãƒ•ã‚¡ã‚¤ãƒ«å + åˆ¶å®šå¹´ + åŒºåˆ†ã®çµ„ã¿åˆã‚ã›ï¼‰
    processed_files = set()
    
    # æ—¢å­˜ã®CSVã‚’èª­ã¿è¾¼ã¿ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
    existing_df = None
    if os.path.exists(output_csv):
        try:
            existing_df = pd.read_csv(output_csv)
            if len(existing_df) > 0:
                print(f"æ—¢å­˜ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {len(existing_df)} è¡Œ")
                # æ—¢å­˜ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’å‡¦ç†æ¸ˆã¿ã‚»ãƒƒãƒˆã«è¿½åŠ 
                for _, row in existing_df.iterrows():
                    key = f"{row['è‡ªæ²»ä½“']}_{row['åˆ¶å®šå¹´']}_{row['åŒºåˆ†']}"
                    processed_files.add(key)
            else:
                print("æ—¢å­˜ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã¯ç©ºã§ã™ã€‚æ–°è¦ä½œæˆã—ã¾ã™ã€‚")
                existing_df = None
        except (pd.errors.EmptyDataError, pd.errors.ParserError) as e:
            print(f"æ—¢å­˜ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
            print("æ–°ã—ã„CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã™ã€‚")
            existing_df = None
    
    # å„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
    for directory in directories:
        if not os.path.exists(directory):
            print(f"âš ï¸  ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {directory}")
            continue
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã‹ã‚‰åˆ¶å®šå¹´ã‚’æŠ½å‡º
        seiteinen = extract_year_from_directory(directory)
        if not seiteinen:
            print(f"âš ï¸  ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã‹ã‚‰åˆ¶å®šå¹´ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“: {directory}")
            continue
        
        print(f"\nğŸ“ å‡¦ç†ä¸­: {directory} (åˆ¶å®šå¹´: {seiteinen})")
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ã™ã¹ã¦ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
        txt_files = glob.glob(os.path.join(directory, '*.txt'))
        print(f"   {len(txt_files)} å€‹ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
        
        for txt_file in txt_files:
            try:
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
                with open(txt_file, 'r', encoding='utf-8') as f:
                    text = f.read()
                
                # ãƒ†ã‚­ã‚¹ãƒˆã‚’æ•´å½¢
                formatted_text = format_text(text)
                
                # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
                filename = os.path.basename(txt_file)
                jichitai, kubun = extract_metadata_from_filename(filename)
                
                # é‡è¤‡ãƒã‚§ãƒƒã‚¯ç”¨ã®ã‚­ãƒ¼ã‚’ä½œæˆ
                key = f"{jichitai}_{seiteinen}_{kubun}"
                
                # é‡è¤‡ãƒã‚§ãƒƒã‚¯
                if key in processed_files:
                    print(f"   âš ï¸  é‡è¤‡ã‚¹ã‚­ãƒƒãƒ—: {filename} ({jichitai}, {seiteinen}, {kubun})")
                    duplicate_count += 1
                    continue  # é‡è¤‡ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                
                # å‡¦ç†æ¸ˆã¿ã‚»ãƒƒãƒˆã«è¿½åŠ 
                processed_files.add(key)
                
                # ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                row_data = {
                    'æœ¬æ–‡': formatted_text,
                    'åˆ¶å®šå¹´': seiteinen,
                    'è‡ªæ²»ä½“': jichitai,
                    'åŒºåˆ†': kubun
                }
                all_data.append(row_data)
                
                print(f"   âœ“ å‡¦ç†å®Œäº†: {filename} ({jichitai}, {seiteinen}, {kubun})")
                success_count += 1
            
            except Exception as e:
                print(f"   âœ— ã‚¨ãƒ©ãƒ¼: {filename} - {str(e)}")
                error_count += 1
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
    if all_data:
        new_df = pd.DataFrame(all_data)
        
        # æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã¨çµåˆ
        if existing_df is not None:
            final_df = pd.concat([existing_df, new_df], ignore_index=True)
        else:
            final_df = new_df
        
        # CSVã«ä¿å­˜
        final_df.to_csv(output_csv, index=False, encoding='utf-8')
        print(f"\n{'='*60}")
        print(f"ğŸ“Š å‡¦ç†å®Œäº†")
        print(f"{'='*60}")
        print(f"âœ“ æˆåŠŸ: {success_count} ä»¶")
        print(f"âœ— ã‚¨ãƒ©ãƒ¼: {error_count} ä»¶")
        print(f"âš ï¸  é‡è¤‡: {duplicate_count} ä»¶")
        print(f"ğŸ“„ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_csv}")
        print(f"ğŸ“ˆ CSVã®ç·è¡Œæ•°: {len(final_df)} è¡Œ")
        print(f"{'='*60}")
    else:
        print("\nâš ï¸  å‡¦ç†ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
    
    return success_count, error_count, duplicate_count

def main(year_input=None, output_csv=None):
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("="*60)
    print("è¤‡æ•°ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«æ•´å½¢ãƒ„ãƒ¼ãƒ«")
    print("="*60)
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®è¨­å®š
    if output_csv is None:
        output_csv = 'main2.6.csv'
    
    # å¹´ã®ç¯„å›²ã¾ãŸã¯å˜å¹´ã‹ã‚‰å‡¦ç†å¯¾è±¡ã‚’æ±ºå®š
    if year_input:
        years = parse_year_range(year_input)
        print(f"æŒ‡å®šã•ã‚ŒãŸå¹´: {', '.join(years)}")
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯åˆ©ç”¨å¯èƒ½ãªå…¨ã¦ã®å¹´ã‚’ä½¿ç”¨
        available_years = get_available_years()
        if available_years:
            years = available_years
            print(f"å¹´ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚åˆ©ç”¨å¯èƒ½ãªå…¨ã¦ã®å¹´ã‚’å‡¦ç†ã—ã¾ã™: {', '.join(years)}")
        else:
            print("ã‚¨ãƒ©ãƒ¼: å‡¦ç†å¯¾è±¡ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            print("å¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå½¢å¼: out_YYYY, out_txt_YYYY")
            sys.exit(1)
    
    # å‡¦ç†å¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—
    target_dirs = get_target_directories(years)
    
    if not target_dirs:
        print("âš ï¸  ã‚¨ãƒ©ãƒ¼: å‡¦ç†å¯¾è±¡ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print("   'out_YYYY' ã¾ãŸã¯ 'out_txt_YYYY' å½¢å¼ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        sys.exit(1)
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¡¨ç¤º
    print(f"\næ¤œå‡ºã•ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª:")
    for directory in sorted(target_dirs):
        year = extract_year_from_directory(directory)
        txt_count = len(glob.glob(os.path.join(directory, '*.txt')))
        print(f"  - {directory} (åˆ¶å®šå¹´: {year}, ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {txt_count})")
    
    # ç¢ºèª
    print(f"\nå‡ºåŠ›å…ˆ: {output_csv}")
    print(f"å‡¦ç†å¯¾è±¡å¹´: {', '.join(years)}")
    print(f"å‡¦ç†ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ•°: {len(target_dirs)}")
    
    # å‡¦ç†ã‚’å®Ÿè¡Œ
    print("\nå‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...\n")
    success_count, error_count, duplicate_count = process_multiple_files(target_dirs, output_csv)
    
    # çµ‚äº†
    if error_count > 0:
        sys.exit(1)
    else:
        sys.exit(0)

if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description="è¤‡æ•°ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«æ•´å½¢ãƒ„ãƒ¼ãƒ« - out_xxxx ã¨ out_txt_xxxx ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‡¦ç†",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  python text_forming.py                       # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆå…¨ã¦ã®åˆ©ç”¨å¯èƒ½ãªå¹´ï¼‰
  python text_forming.py --year 2014           # out_2014 ã¨ out_txt_2014 ã‚’å‡¦ç†
  python text_forming.py -y 2015               # out_2015 ã¨ out_txt_2015 ã‚’å‡¦ç†
  python text_forming.py --year 2014-2018      # 2014å¹´ã‹ã‚‰2018å¹´ã¾ã§é †æ¬¡å‡¦ç†
  python text_forming.py -y 2016-2017          # 2016å¹´ã¨2017å¹´ã‚’å‡¦ç†
  python text_forming.py --list-years          # åˆ©ç”¨å¯èƒ½ãªå¹´ã®ãƒªã‚¹ãƒˆã‚’è¡¨ç¤º
  python text_forming.py --output custom.csv   # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æŒ‡å®š
        """
    )
    parser.add_argument("--year", "-y", type=str, help="å‡¦ç†å¯¾è±¡ã®å¹´ï¼ˆä¾‹: 2014, 2015, 2014-2018ï¼‰")
    parser.add_argument("--output", "-o", type=str, default="main2.6.csv", help="å‡ºåŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: main2.6.csvï¼‰")
    parser.add_argument("--list-years", "-l", action="store_true", help="åˆ©ç”¨å¯èƒ½ãªå¹´ã®ãƒªã‚¹ãƒˆã‚’è¡¨ç¤º")
    
    args = parser.parse_args()
    
    if args.list_years:
        available_years = get_available_years()
        if available_years:
            print("åˆ©ç”¨å¯èƒ½ãªå¹´:")
            for year in available_years:
                out_dir = f"out_{year}"
                out_txt_dir = f"out_txt_{year}"
                
                out_exists = "âœ“" if os.path.exists(out_dir) else "âœ—"
                out_txt_exists = "âœ“" if os.path.exists(out_txt_dir) else "âœ—"
                
                print(f"  {year}: out_{year} {out_exists}  out_txt_{year} {out_txt_exists}")
        else:
            print("å¹´åˆ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            print("å¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå½¢å¼: out_YYYY, out_txt_YYYY")
        sys.exit(0)
    
    try:
        main(year_input=args.year, output_csv=args.output)
    except KeyboardInterrupt:
        print("\n\nå‡¦ç†ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        sys.exit(1)
    except Exception as e:
        print(f"\näºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)